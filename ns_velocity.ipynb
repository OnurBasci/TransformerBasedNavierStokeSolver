{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import *\n",
    "from utils.testloss import TestLoss\n",
    "from model import Transolver_Structured_Mesh_2D\n",
    "from phi.torch.flow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 8\n",
    "n_hidden = 64\n",
    "droupout = 0.0\n",
    "heads = 4\n",
    "mlp_ratio = 1\n",
    "lr = 0.001\n",
    "slice_num = 32\n",
    "unified_pos = 0\n",
    "ref = 8\n",
    "weight_decay = 1e-5\n",
    "max_grad_norm = None\n",
    "batch_size = 2\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 64, 64, 40)\n",
      "torch.Size([16, 4096, 10])\n",
      "torch.Size([16, 4096, 10])\n",
      "torch.Size([4, 4096, 10])\n",
      "torch.Size([4, 4096, 10])\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\\\Users\\\\onurb\\\\master\\\\PRJ_4ID22_TP\\\\Transolver\\\\PDE-Solving-StandardBenchmark\\\\data\\\\ns_20_20.npy\"\n",
    "save_name = \"buff\"\n",
    "# data_path = args.data_path + '/NavierStokes_V1e-5_N1200_T20.mat'\n",
    "ntrain = 16\n",
    "ntest = 4\n",
    "T_in = 10\n",
    "T = 10\n",
    "step = 2 #step is 2 since we have velx, vely\n",
    "\n",
    "r = 1\n",
    "h = int(((64 - 1) / r) + 1)\n",
    "\n",
    "data = np.load(data_path)\n",
    "print(data.shape)\n",
    "#a is the frames until the time T u is the frames after the time T\n",
    "train_a = data[:ntrain, ::r, ::r, :T_in][:, :h, :h, :]\n",
    "train_a = train_a.reshape(train_a.shape[0], -1, train_a.shape[-1])\n",
    "train_a = torch.from_numpy(train_a)\n",
    "train_u = data[:ntrain, ::r, ::r, T_in:T + T_in][:, :h, :h, :]\n",
    "train_u = train_u.reshape(train_u.shape[0], -1, train_u.shape[-1])\n",
    "train_u = torch.from_numpy(train_u)\n",
    "\n",
    "test_a = data[-ntest:, ::r, ::r, :T_in][:, :h, :h, :]\n",
    "test_a = test_a.reshape(test_a.shape[0], -1, test_a.shape[-1])\n",
    "test_a = torch.from_numpy(test_a)\n",
    "test_u = data[-ntest:, ::r, ::r, T_in:T + T_in][:, :h, :h, :]\n",
    "test_u = test_u.reshape(test_u.shape[0], -1, test_u.shape[-1])\n",
    "test_u = torch.from_numpy(test_u)\n",
    "\n",
    "print(train_a.shape)\n",
    "print(train_u.shape)\n",
    "\n",
    "print(test_a.shape)\n",
    "print(test_u.shape)\n",
    "\n",
    "x = np.linspace(0, 1, h)\n",
    "y = np.linspace(0, 1, h)\n",
    "x, y = np.meshgrid(x, y)\n",
    "pos = np.c_[x.ravel(), y.ravel()]\n",
    "pos = torch.tensor(pos, dtype=torch.float).unsqueeze(0)\n",
    "pos_train = pos.repeat(ntrain, 1, 1)\n",
    "pos_test = pos.repeat(ntest, 1, 1)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(pos_train, train_a, train_u),\n",
    "                                            batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(pos_test, test_a, test_u),\n",
    "                                            batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (preprocess): MLP(\n",
      "    (linear_pre): Sequential(\n",
      "      (0): Linear(in_features=12, out_features=128, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "    )\n",
      "    (linear_post): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (linears): ModuleList()\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-6): 7 x Transolver_block(\n",
      "      (ln_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (Attn): Physics_Attention_Structured_Mesh_2D(\n",
      "        (softmax): Softmax(dim=-1)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (in_project_x): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (in_project_fx): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (in_project_slice): Linear(in_features=16, out_features=32, bias=True)\n",
      "        (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
      "        (to_k): Linear(in_features=16, out_features=16, bias=False)\n",
      "        (to_v): Linear(in_features=16, out_features=16, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (linear_pre): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (linear_post): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (linears): ModuleList()\n",
      "      )\n",
      "    )\n",
      "    (7): Transolver_block(\n",
      "      (ln_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (Attn): Physics_Attention_Structured_Mesh_2D(\n",
      "        (softmax): Softmax(dim=-1)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (in_project_x): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (in_project_fx): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (in_project_slice): Linear(in_features=16, out_features=32, bias=True)\n",
      "        (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
      "        (to_k): Linear(in_features=16, out_features=16, bias=False)\n",
      "        (to_v): Linear(in_features=16, out_features=16, bias=False)\n",
      "        (to_out): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (ln_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (linear_pre): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "        )\n",
      "        (linear_post): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (linears): ModuleList()\n",
      "      )\n",
      "      (ln_3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp2): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total Trainable Params: 713506\n"
     ]
    }
   ],
   "source": [
    "model = Transolver_Structured_Mesh_2D.Model(space_dim=2,\n",
    "                                  n_layers=layer,\n",
    "                                  n_hidden=n_hidden,\n",
    "                                  dropout=droupout,\n",
    "                                  n_head=heads,\n",
    "                                  Time_Input=False,\n",
    "                                  mlp_ratio=mlp_ratio,\n",
    "                                  fun_dim=T_in,\n",
    "                                  out_dim=2,                #!!!!Output dimenstion is 2 since we calculate a velocity field\n",
    "                                  slice_num=slice_num,\n",
    "                                  ref=ref,\n",
    "                                  unified_pos=unified_pos,\n",
    "                                  H=h, W=h).cuda()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "print(model)\n",
    "\n",
    "def count_parameters(model):\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        total_params += params\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "count_parameters(model)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, epochs=epochs,\n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "myloss = TestLoss(size_average=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 0 , train_step_loss:0.72347 , train_full_loss:0.72365 , test_step_loss:0.57462 , test_full_loss:0.57708\n",
      "save model\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 1 , train_step_loss:0.34407 , train_full_loss:0.34459 , test_step_loss:0.39500 , test_full_loss:0.39781\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 2 , train_step_loss:0.24314 , train_full_loss:0.24370 , test_step_loss:0.33578 , test_full_loss:0.34028\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 3 , train_step_loss:0.21378 , train_full_loss:0.21415 , test_step_loss:0.27619 , test_full_loss:0.27980\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 4 , train_step_loss:0.18116 , train_full_loss:0.18144 , test_step_loss:0.24102 , test_full_loss:0.24616\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 5 , train_step_loss:0.16125 , train_full_loss:0.16145 , test_step_loss:0.29075 , test_full_loss:0.30078\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 6 , train_step_loss:0.12535 , train_full_loss:0.12560 , test_step_loss:0.21563 , test_full_loss:0.22272\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 7 , train_step_loss:0.13981 , train_full_loss:0.13990 , test_step_loss:0.34474 , test_full_loss:0.36723\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 8 , train_step_loss:0.22840 , train_full_loss:0.22831 , test_step_loss:0.37072 , test_full_loss:0.38763\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 9 , train_step_loss:0.15578 , train_full_loss:0.15582 , test_step_loss:0.20336 , test_full_loss:0.21391\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 10 , train_step_loss:0.13178 , train_full_loss:0.13181 , test_step_loss:0.20179 , test_full_loss:0.20972\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 11 , train_step_loss:0.13285 , train_full_loss:0.13292 , test_step_loss:0.36625 , test_full_loss:0.39609\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 12 , train_step_loss:0.13840 , train_full_loss:0.13848 , test_step_loss:0.23694 , test_full_loss:0.25580\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 13 , train_step_loss:0.13363 , train_full_loss:0.13367 , test_step_loss:0.28499 , test_full_loss:0.30900\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 14 , train_step_loss:0.11710 , train_full_loss:0.11720 , test_step_loss:0.31815 , test_full_loss:0.34167\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 15 , train_step_loss:0.11335 , train_full_loss:0.11339 , test_step_loss:0.30355 , test_full_loss:0.32388\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 16 , train_step_loss:0.13795 , train_full_loss:0.13795 , test_step_loss:0.33320 , test_full_loss:0.35698\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 17 , train_step_loss:0.13954 , train_full_loss:0.13959 , test_step_loss:0.28107 , test_full_loss:0.30413\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 18 , train_step_loss:0.11173 , train_full_loss:0.11182 , test_step_loss:0.24590 , test_full_loss:0.26351\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 19 , train_step_loss:0.09415 , train_full_loss:0.09431 , test_step_loss:0.26914 , test_full_loss:0.29153\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 20 , train_step_loss:0.11291 , train_full_loss:0.11295 , test_step_loss:0.30391 , test_full_loss:0.32951\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 21 , train_step_loss:0.08726 , train_full_loss:0.08736 , test_step_loss:0.21293 , test_full_loss:0.23221\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 22 , train_step_loss:0.07335 , train_full_loss:0.07344 , test_step_loss:0.14854 , test_full_loss:0.15711\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 23 , train_step_loss:0.07520 , train_full_loss:0.07528 , test_step_loss:0.15280 , test_full_loss:0.16308\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 24 , train_step_loss:0.07563 , train_full_loss:0.07574 , test_step_loss:0.17768 , test_full_loss:0.19290\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 25 , train_step_loss:0.06306 , train_full_loss:0.06323 , test_step_loss:0.16545 , test_full_loss:0.18051\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 26 , train_step_loss:0.05570 , train_full_loss:0.05591 , test_step_loss:0.11753 , test_full_loss:0.12716\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 27 , train_step_loss:0.06833 , train_full_loss:0.06850 , test_step_loss:0.30278 , test_full_loss:0.33264\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 28 , train_step_loss:0.11046 , train_full_loss:0.11051 , test_step_loss:0.29158 , test_full_loss:0.31797\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 29 , train_step_loss:0.08342 , train_full_loss:0.08350 , test_step_loss:0.15720 , test_full_loss:0.17051\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 30 , train_step_loss:0.05216 , train_full_loss:0.05234 , test_step_loss:0.14784 , test_full_loss:0.16107\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 31 , train_step_loss:0.04278 , train_full_loss:0.04307 , test_step_loss:0.12762 , test_full_loss:0.13882\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 32 , train_step_loss:0.03962 , train_full_loss:0.03996 , test_step_loss:0.12520 , test_full_loss:0.13569\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 33 , train_step_loss:0.04333 , train_full_loss:0.04360 , test_step_loss:0.15208 , test_full_loss:0.16622\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 34 , train_step_loss:0.04276 , train_full_loss:0.04306 , test_step_loss:0.10396 , test_full_loss:0.11254\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 35 , train_step_loss:0.03966 , train_full_loss:0.03996 , test_step_loss:0.11923 , test_full_loss:0.12992\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 36 , train_step_loss:0.03345 , train_full_loss:0.03390 , test_step_loss:0.09696 , test_full_loss:0.10472\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 37 , train_step_loss:0.03057 , train_full_loss:0.03105 , test_step_loss:0.09861 , test_full_loss:0.10655\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 38 , train_step_loss:0.03010 , train_full_loss:0.03060 , test_step_loss:0.09668 , test_full_loss:0.10440\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 39 , train_step_loss:0.02952 , train_full_loss:0.03004 , test_step_loss:0.09561 , test_full_loss:0.10334\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 40 , train_step_loss:0.02963 , train_full_loss:0.03013 , test_step_loss:0.09703 , test_full_loss:0.10484\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 41 , train_step_loss:0.02938 , train_full_loss:0.02989 , test_step_loss:0.09877 , test_full_loss:0.10686\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 42 , train_step_loss:0.02930 , train_full_loss:0.02980 , test_step_loss:0.09779 , test_full_loss:0.10574\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 43 , train_step_loss:0.02877 , train_full_loss:0.02928 , test_step_loss:0.09533 , test_full_loss:0.10311\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 44 , train_step_loss:0.02867 , train_full_loss:0.02920 , test_step_loss:0.09468 , test_full_loss:0.10242\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 45 , train_step_loss:0.02861 , train_full_loss:0.02913 , test_step_loss:0.09602 , test_full_loss:0.10385\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 46 , train_step_loss:0.02848 , train_full_loss:0.02901 , test_step_loss:0.09421 , test_full_loss:0.10187\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 47 , train_step_loss:0.02831 , train_full_loss:0.02884 , test_step_loss:0.09407 , test_full_loss:0.10173\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 48 , train_step_loss:0.02828 , train_full_loss:0.02881 , test_step_loss:0.09424 , test_full_loss:0.10190\n",
      "8\n",
      "training data 0\n",
      "training data 1\n",
      "training data 2\n",
      "training data 3\n",
      "training data 4\n",
      "training data 5\n",
      "training data 6\n",
      "training data 7\n",
      "Epoch 49 , train_step_loss:0.02824 , train_full_loss:0.02877 , test_step_loss:0.09426 , test_full_loss:0.10193\n",
      "[11.492362976074219, 7.899997234344482, 6.715697526931763, 5.523741960525513, 4.820392370223999, 5.8149733543396, 4.312644004821777, 6.894718170166016, 7.414415597915649, 4.067143440246582, 4.035882592201233, 7.32503342628479, 4.73881196975708, 5.699793815612793, 6.36293888092041, 6.0710625648498535, 6.664076566696167, 5.621477842330933, 4.91804313659668, 5.382894277572632, 6.078240156173706, 4.258671998977661, 2.9707114696502686, 3.0559109449386597, 3.553659200668335, 3.308950901031494, 2.350503921508789, 6.055518865585327, 5.831525802612305, 3.143934726715088, 2.956897258758545, 2.552483916282654, 2.5039947032928467, 3.041647791862488, 2.0791237354278564, 2.384676218032837, 1.9391875863075256, 1.972262978553772, 1.933537244796753, 1.9122769832611084, 1.9405573606491089, 1.9754911065101624, 1.9558073282241821, 1.906690776348114, 1.8935517072677612, 1.9204979538917542, 1.8841621279716492, 1.881459355354309, 1.8847061395645142, 1.8852714896202087]\n",
      "save model\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    train_l2_step = 0\n",
    "    train_l2_full = 0\n",
    "\n",
    "    print(len(train_loader))\n",
    "    for i, (x, fx, yy) in enumerate(train_loader):\n",
    "        print(f\"training data {i}\")\n",
    "        #print(f\"fx shape {fx.shape}, yy shape {yy.shape}\")\n",
    "        #print(f\"x {x.size()}, fx {fx.size()}, yy {yy.size()}\")\n",
    "        loss = 0\n",
    "        x, fx, yy = x.cuda(), fx.cuda(), yy.cuda()  # x: B,4096,2    fx: B,4096,T   y: B,4096,T\n",
    "        bsz = x.shape[0]\n",
    "\n",
    "        for t in range(0, T, step):\n",
    "            #print(f\"t is {t}\")\n",
    "            y = yy[..., t:t + step]\n",
    "            #print(f\"x {x.shape}, fx {fx.shape}\")\n",
    "            im = model(x, fx=fx)  # B , 4096 , 1\n",
    "            loss += myloss(im.reshape(bsz, -1), y.reshape(bsz, -1))\n",
    "            #print(torch.sum(torch.pow(im.reshape(1, -1) - y.reshape(1, -1),2)))\n",
    "            if t == 0:\n",
    "                pred = im\n",
    "            else:\n",
    "                pred = torch.cat((pred, im), -1)\n",
    "            #we add the ground truth to the fx not th+e prediction\n",
    "            #from frame (t: t+T) to (t+1: t+T+1) \n",
    "            fx = torch.cat((fx[..., step:], y), dim=-1)  # detach() & groundtruth\n",
    "            #print(f\"fx shape {fx.shape} im shape {im.shape} y shape {y.shape} x shape {x.shape}\")\n",
    "\n",
    "        train_l2_step += loss.item()\n",
    "        train_l2_full += myloss(pred.reshape(bsz, -1), yy.reshape(bsz, -1)).item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if max_grad_norm is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    test_l2_step = 0\n",
    "    test_l2_full = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, fx, yy in test_loader:\n",
    "            loss = 0\n",
    "            x, fx, yy = x.cuda(), fx.cuda(), yy.cuda()  # x : B, 4096, 2  fx : B, 4096  y : B, 4096, T\n",
    "            bsz = x.shape[0]\n",
    "            for t in range(0, T, step):\n",
    "                y = yy[..., t:t + step]\n",
    "                im = model(x, fx=fx)\n",
    "                loss += myloss(im.reshape(bsz, -1), y.reshape(bsz, -1))\n",
    "                if t == 0:\n",
    "                    pred = im\n",
    "                else:\n",
    "                    pred = torch.cat((pred, im), -1)\n",
    "                fx = torch.cat((fx[..., step:], im), dim=-1)\n",
    "\n",
    "            test_l2_step += loss.item()\n",
    "            test_l2_full += myloss(pred.reshape(bsz, -1), yy.reshape(bsz, -1)).item()\n",
    "        \n",
    "        test_losses.append(test_l2_step)\n",
    "\n",
    "    print(\n",
    "        \"Epoch {} , train_step_loss:{:.5f} , train_full_loss:{:.5f} , test_step_loss:{:.5f} , test_full_loss:{:.5f}\".format(\n",
    "            ep, train_l2_step / ntrain / (T / step), train_l2_full / ntrain, test_l2_step / ntest / (T / step),\n",
    "                test_l2_full / ntest))\n",
    "\n",
    "    if ep % 100 == 0:\n",
    "        if not os.path.exists('./checkpoints'):\n",
    "            os.makedirs('./checkpoints')\n",
    "        print('save model')\n",
    "        torch.save(model.state_dict(), os.path.join('./checkpoints', save_name + '.pt'))\n",
    "\n",
    "print(test_losses)\n",
    "if not os.path.exists('./checkpoints'):\n",
    "    os.makedirs('./checkpoints')\n",
    "print('save model')\n",
    "torch.save(model.state_dict(), os.path.join('./checkpoints', save_name + '.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
